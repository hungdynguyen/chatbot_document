import requests
import json
import asyncio
from typing import List, Dict

# Import t·ª´ config
from config import LANGFLOW_EXTRACTOR_URL, HEADERS, QDRANT_COMPONENT_ID_EXTRACTOR

# (QDRANT_COMPONENT_ID ƒë∆∞·ª£c import t·ª´ config) 

MAX_ITERATIONS = 20
INITIAL_BATCH_SIZE = 6
MIN_BATCH_SIZE_TO_SPLIT = 2

FIELDS_TO_EXTRACT = [
    "t√™n ƒë·∫ßy ƒë·ªß c·ªßa doanh nghi·ªáp",
    "m√£ s·ªë doanh nghi·ªáp",
    "ng√†y c·∫•p gi·∫•y ch·ª©ng nh·∫≠n ƒëƒÉng k√Ω kinh doanh",
    "n∆°i c·∫•p gi·∫•y ch·ª©ng nh·∫≠n ƒëƒÉng k√Ω kinh doanh",
    "ƒë·ªãa ch·ªâ tr·ª• s·ªü ch√≠nh",
    "ng√†nh ngh·ªÅ kinh doanh ch√≠nh",
    "v·ªën ƒëi·ªÅu l·ªá",
    "t√™n ng∆∞·ªùi ƒë·∫°i di·ªán theo ph√°p lu·∫≠t",
    "ch·ª©c v·ª• ng∆∞·ªùi ƒë·∫°i di·ªán",
    "s·ªë CCCD/CMND c·ªßa ng∆∞·ªùi ƒë·∫°i di·ªán",
    "s·ªë ti·ªÅn ƒë·ªÅ ngh·ªã vay",
    "th·ªùi h·∫°n vay (th√°ng)",
    "m·ª•c ƒë√≠ch vay v·ªën",
    "s·∫£n ph·∫©m t√≠n d·ª•ng ƒëƒÉng k√Ω",
    "l√£i su·∫•t cho vay (%/nƒÉm)",
    "ph√≠ tr·∫£ n·ª£ tr∆∞·ªõc h·∫°n (%)",
    "ph∆∞∆°ng th·ª©c tr·∫£ n·ª£",
    "doanh thu nƒÉm g·∫ßn nh·∫•t",
    "l·ª£i nhu·∫≠n r√≤ng nƒÉm g·∫ßn nh·∫•t",
    "t·ªïng t√†i s·∫£n ∆∞·ªõc t√≠nh",
    "d·ª± b√°o doanh thu nƒÉm 1 sau khi vay",
    "k·∫ø ho·∫°ch ph√¢n b·ªï v·ªën vay cho ƒë·∫ßu t∆∞ kho l·∫°nh",
    "ƒëi·ªÉm t√≠n d·ª•ng doanh nghi·ªáp (CIC)",
    "x·∫øp h·∫°ng t√≠n d·ª•ng doanh nghi·ªáp (CIC)",
    "ph√¢n lo·∫°i n·ª£ hi·ªán t·∫°i c·ªßa doanh nghi·ªáp (CIC)",
    "t·ªïng d∆∞ n·ª£ t·∫°i c√°c t·ªï ch·ª©c t√≠n d·ª•ng kh√°c",
    "d∆∞ n·ª£ t·∫°i Vietcombank (CIC)",
    "l·ªãch s·ª≠ tr·∫£ n·ª£ 12 th√°ng g·∫ßn nh·∫•t (chu·ªói tr·∫°ng th√°i CIC)",
    "lo·∫°i t√†i s·∫£n b·∫£o ƒë·∫£m ch√≠nh",
    "ch·ªß s·ªü h·ªØu t√†i s·∫£n b·∫£o ƒë·∫£m",
    "gi√° tr·ªã t√†i s·∫£n b·∫£o ƒë·∫£m theo th·∫©m ƒë·ªãnh",
    "ƒë∆°n v·ªã th·∫©m ƒë·ªãnh gi√°",
    "t·ª∑ l·ªá cho vay t·ªëi ƒëa tr√™n t√†i s·∫£n b·∫£o ƒë·∫£m (%)",
    "t√™n ng∆∞·ªùi b·∫£o l√£nh cho kho·∫£n vay"
]

# --- 2. C√ÅC H√ÄM H·ªñ TR·ª¢ ---

def create_prompt(fields_list: list) -> str:
    """T·∫°o prompt ƒë·ªÉ y√™u c·∫ßu LLM tr√≠ch xu·∫•t c√°c tr∆∞·ªùng th√¥ng tin c·ª• th·ªÉ."""
    if not fields_list:
        return ""
    fields_as_text_list = "\n- ".join(fields_list)
    if len(fields_list) == 1:
        return f"{fields_as_text_list}"
    else:
        return f"- {fields_as_text_list}"

def is_valid_value(value) -> bool:
    """Ki·ªÉm tra xem gi√° tr·ªã tr√≠ch xu·∫•t c√≥ h·ª£p l·ªá hay kh√¥ng."""
    return value is not None and str(value).strip() != ""

# --- H√ÄM QUERY LANGFLOW ƒê√É N√ÇNG C·∫§P HO√ÄN CH·ªàNH ---
def query_langflow_for_json(question_prompt: str, collection_name: str) -> dict:
    """
    G·ª≠i y√™u c·∫ßu ƒë·∫øn Langflow, S·ª¨ D·ª§NG TWEAKS ƒë·ªÉ ch·ªâ ƒë·ªãnh collection_name ƒë·ªông.
    """
    if not question_prompt:
        return {}

    # Payload gi·ªù ƒë√¢y s·∫Ω ghi ƒë√® collection_name c·ªßa component Qdrant trong flow
    payload = {
        "input_value": question_prompt,
        "output_type": "chat",
        "input_type": "chat",
        "tweaks": {
            QDRANT_COMPONENT_ID_EXTRACTOR: {
                "collection_name": collection_name
            }
        }
    }
    
    print(f"  - ƒêang g·ª≠i y√™u c·∫ßu t·ªõi Langflow, ghi ƒë√® collection th√†nh: '{collection_name}'")

    try:
        response = requests.post(LANGFLOW_EXTRACTOR_URL, json=payload, headers=HEADERS, timeout=120)
        response.raise_for_status()
        
        langflow_data = response.json()
        # ƒê∆∞·ªùng d·∫´n t·ªõi message c√≥ th·ªÉ thay ƒë·ªïi t√πy theo c·∫•u tr√∫c flow, c·∫ßn ki·ªÉm tra k·ªπ
        llm_response_text = langflow_data['outputs'][0]['outputs'][0]['results']['message']['text']
        
        start = llm_response_text.find('{')
        end = llm_response_text.rfind('}')
        
        if start != -1 and end != -1:
            json_str = llm_response_text[start : end + 1]
            # Th√™m try-except ƒë·ªÉ b·∫Øt l·ªói JSON kh√¥ng h·ª£p l·ªá
            try:
                return json.loads(json_str)
            except json.JSONDecodeError:
                print(f"  - L·ªói: Chu·ªói JSON kh√¥ng h·ª£p l·ªá: {json_str}")
                return {}
        else:
            print("  - L·ªói: Kh√¥ng t√¨m th·∫•y ƒë·ªëi t∆∞·ª£ng JSON h·ª£p l·ªá trong ph·∫£n h·ªìi c·ªßa LLM.")
            return {}
            
    except requests.exceptions.RequestException as e:
        print(f"  - L·ªói k·∫øt n·ªëi t·ªõi Langflow: {e}")
        return {}
    except (KeyError, IndexError) as e:
        print(f"  - L·ªói: C·∫•u tr√∫c ph·∫£n h·ªìi t·ª´ Langflow kh√¥ng nh∆∞ mong ƒë·ª£i. L·ªói: {e}")
        print(f"  - Ph·∫£n h·ªìi nh·∫≠n ƒë∆∞·ª£c: {langflow_data}")
        return {}
    except Exception as e:
        print(f"  - L·ªói kh√¥ng x√°c ƒë·ªãnh khi query Langflow: {e}")
        return {}


# --- 3. LOGIC TR√çCH XU·∫§T CH√çNH (ƒê√É N√ÇNG C·∫§P HO√ÄN CH·ªàNH) ---

async def extract_information_from_docs(prompt: str, file_ids: List[str], collection_name: str) -> Dict:
    """
    H√†m ch√≠nh ƒëi·ªÅu khi·ªÉn lu·ªìng tr√≠ch xu·∫•t th√¥ng tin th√¥ng minh,
    gi·ªù ƒë√¢y nh·∫≠n `collection_name` ƒë·ªÉ query ƒë√∫ng v√†o VectorDB c·ªßa phi√™n l√†m vi·ªác.
    """
    final_result = {}
    work_queue = [
        FIELDS_TO_EXTRACT[i:i + INITIAL_BATCH_SIZE]
        for i in range(0, len(FIELDS_TO_EXTRACT), INITIAL_BATCH_SIZE)
    ]
    current_iteration = 0
    print(f"üöÄ B·∫Øt ƒë·∫ßu qu√° tr√¨nh tr√≠ch xu·∫•t th√¥ng tin t·ª´ collection '{collection_name}'...")

    while work_queue and current_iteration < MAX_ITERATIONS:
        current_iteration += 1
        current_batch = work_queue.pop(0)
        
        print(f"\n--- V√íNG L·∫∂P {current_iteration}/{MAX_ITERATIONS} | ƒêang x·ª≠ l√Ω l√¥ {len(current_batch)} tr∆∞·ªùng ---")
        
        batch_prompt = create_prompt(current_batch)
        
        # Ch·∫°y h√†m requests ƒë·ªìng b·ªô trong m·ªôt lu·ªìng ri√™ng ƒë·ªÉ kh√¥ng ch·∫∑n v√≤ng l·∫∑p s·ª± ki·ªán c·ªßa FastAPI
        loop = asyncio.get_event_loop()
        # Truy·ªÅn collection_name v√†o h√†m query
        response_json = await loop.run_in_executor(
            None, query_langflow_for_json, batch_prompt, collection_name
        )

        newly_found_fields = []
        if response_json:
            for field in current_batch:
                if field in response_json and is_valid_value(response_json[field]):
                    value = response_json[field]
                    print(f"    ‚úÖ ƒê√£ t√¨m th·∫•y '{field}': {value}")
                    final_result[field] = value
                    newly_found_fields.append(field)
        
        failed_fields = [f for f in current_batch if f not in newly_found_fields]
        
        if failed_fields:
            print(f"  - Kh√¥ng t√¨m th·∫•y {len(failed_fields)} tr∆∞·ªùng: {', '.join(failed_fields)}")
            if len(failed_fields) >= MIN_BATCH_SIZE_TO_SPLIT:
                print(f"  -> Chia nh·ªè l√¥ th·∫•t b·∫°i...")
                mid_point = len(failed_fields) // 2
                first_half = failed_fields[:mid_point]
                second_half = failed_fields[mid_point:]
                work_queue.insert(0, second_half)
                work_queue.insert(0, first_half)
            else:
                print(f"  -> L√¥ qu√° nh·ªè, kh√¥ng chia n·ªØa.")
        
        await asyncio.sleep(1) # C√≥ th·ªÉ gi·∫£m th·ªùi gian sleep

    print("\n\n‚úÖ Qu√° tr√¨nh tr√≠ch xu·∫•t ho√†n t·∫•t!")
    
    # Tr·∫£ v·ªÅ k·∫øt qu·∫£ cu·ªëi c√πng d∆∞·ªõi d·∫°ng m·ªôt dictionary
    return final_result