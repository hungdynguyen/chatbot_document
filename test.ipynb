{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d3d0663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ l∆∞u embedding Vietnamese KB v√†o Qdrant v·ªõi m√¥ h√¨nh MiniLM!\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# 1. Load v√† chia nh·ªè vƒÉn b·∫£n\n",
    "loader = TextLoader(\"KH001_Don_Xin_Vay_Von.txt\", encoding=\"utf-8\")\n",
    "docs = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    ").split_documents(loader.load())\n",
    "\n",
    "# 2. Kh·ªüi t·∫°o embedding model: paraphrase-multilingual-MiniLM-L12-v2\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"}  # ho·∫∑c \"cuda\"\n",
    ")\n",
    "\n",
    "# 3. K·∫øt n·ªëi t·ªõi Qdrant\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "# 4. X√≥a v√† t·∫°o l·∫°i collection v·ªõi ƒë√∫ng dimension (384) & distance\n",
    "client.recreate_collection(\n",
    "    collection_name=\"viet_kb\",\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "# 5. Kh·ªüi t·∫°o Qdrant vectorstore\n",
    "qdrant = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=\"viet_kb\",\n",
    "    embeddings=embedding_model\n",
    ")\n",
    "\n",
    "# 6. Th√™m documents v√†o vectordb\n",
    "qdrant.add_documents(documents=docs, batch_size=64)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ l∆∞u embedding Vietnamese KB v√†o Qdrant v·ªõi m√¥ h√¨nh MiniLM!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895e0991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ƒêang t√¨m v√† t·∫£i c√°c file t·ª´ th∆∞ m·ª•c 'data/data1'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ƒêang t·∫£i c√°c file: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 104.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng 4 document t·ª´ 4 file.\n",
      "üîÑ ƒêang chia nh·ªè vƒÉn b·∫£n v·ªõi chunk_size=1200 v√† chunk_overlap=200...\n",
      "‚úÖ ƒê√£ chia th√†nh 11 chunk ƒë·ªÉ chu·∫©n b·ªã embedding.\n",
      "üß† ƒêang kh·ªüi t·∫°o embedding model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model ƒë√£ s·∫µn s√†ng. K√≠ch th∆∞·ªõc vector: 384\n",
      "‚òÅÔ∏è ƒêang k·∫øt n·ªëi t·ªõi Qdrant v√† t·∫°o collection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52034/1221667981.py:61: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Collection 'viet_kb' ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng.\n",
      "‚è≥ ƒêang th·ª±c hi·ªán embedding v√† l∆∞u v√†o Qdrant. Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t...\n",
      "\n",
      "üéâ HO√ÄN T·∫§T! To√†n b·ªô d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c embedding v√† l∆∞u v√†o Qdrant.\n",
      "üëâ B√¢y gi·ªù b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng collection 'viet_kb' trong Langflow.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from tqdm import tqdm # Th∆∞ vi·ªán ƒë·ªÉ hi·ªÉn th·ªã thanh ti·∫øn tr√¨nh ƒë·∫πp m·∫Øt\n",
    "\n",
    "# --- 1. C·∫•u h√¨nh ---\n",
    "DATA_DIRECTORY = \"data/data1\"\n",
    "COLLECTION_NAME = \"viet_kb\" # ƒê·∫∑t t√™n m·ªõi ƒë·ªÉ kh√¥ng b·ªã ghi ƒë√® collection c≈©\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "CHUNK_SIZE = 1200 # TƒÉng k√≠ch th∆∞·ªõc chunk ƒë·ªÉ ch·ª©a nhi·ªÅu ng·ªØ c·∫£nh h∆°n\n",
    "CHUNK_OVERLAP = 200 # TƒÉng ƒë·ªô ch·ªìng l·∫•n ƒë·ªÉ tr√°nh c·∫Øt c√¢u\n",
    "\n",
    "# --- 2. T·∫£i t·∫•t c·∫£ c√°c file t·ª´ th∆∞ m·ª•c ---\n",
    "print(f\"üîç ƒêang t√¨m v√† t·∫£i c√°c file t·ª´ th∆∞ m·ª•c '{DATA_DIRECTORY}'...\")\n",
    "all_documents = []\n",
    "# T√¨m t·∫•t c·∫£ c√°c file c√≥ ƒëu√¥i .txt trong th∆∞ m·ª•c data\n",
    "file_paths = glob.glob(os.path.join(DATA_DIRECTORY, \"*.txt\"))\n",
    "\n",
    "if not file_paths:\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y file .txt n√†o trong th∆∞ m·ª•c '{DATA_DIRECTORY}'. Vui l√≤ng ki·ªÉm tra l·∫°i.\")\n",
    "else:\n",
    "    for file_path in tqdm(file_paths, desc=\"ƒêang t·∫£i c√°c file\"):\n",
    "        try:\n",
    "            loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "            all_documents.extend(loader.load())\n",
    "        except Exception as e:\n",
    "            print(f\"L·ªói khi t·∫£i file {file_path}: {e}\")\n",
    "    \n",
    "    print(f\"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng {len(all_documents)} document t·ª´ {len(file_paths)} file.\")\n",
    "\n",
    "    # --- 3. Chia nh·ªè to√†n b·ªô vƒÉn b·∫£n ---\n",
    "    print(f\"üîÑ ƒêang chia nh·ªè vƒÉn b·∫£n v·ªõi chunk_size={CHUNK_SIZE} v√† chunk_overlap={CHUNK_OVERLAP}...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"---\", \".\", \" \"] # Th√™m '---' ƒë·ªÉ c√≥ th·ªÉ t√°ch c√°c file\n",
    "    )\n",
    "    docs_for_db = text_splitter.split_documents(all_documents)\n",
    "    print(f\"‚úÖ ƒê√£ chia th√†nh {len(docs_for_db)} chunk ƒë·ªÉ chu·∫©n b·ªã embedding.\")\n",
    "\n",
    "    # --- 4. Kh·ªüi t·∫°o embedding model ---\n",
    "    print(f\"üß† ƒêang kh·ªüi t·∫°o embedding model: {MODEL_NAME}...\")\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name=MODEL_NAME,\n",
    "        model_kwargs={\"device\": \"cpu\"}  # ƒê·ªïi th√†nh \"cuda\" n·∫øu b·∫°n c√≥ GPU\n",
    "    )\n",
    "    # L·∫•y dimension c·ªßa vector t·ª´ model. MiniLM l√† 384.\n",
    "    embed_dim = embedding_model.client.get_sentence_embedding_dimension()\n",
    "    print(f\"‚úÖ Model ƒë√£ s·∫µn s√†ng. K√≠ch th∆∞·ªõc vector: {embed_dim}\")\n",
    "\n",
    "    # --- 5. K·∫øt n·ªëi v√† t·∫°o l·∫°i collection trong Qdrant ---\n",
    "    print(\"‚òÅÔ∏è ƒêang k·∫øt n·ªëi t·ªõi Qdrant v√† t·∫°o collection...\")\n",
    "    client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "    # X√≥a collection c≈© (n·∫øu c√≥) v√† t·∫°o l·∫°i v·ªõi c·∫•u h√¨nh m·ªõi\n",
    "    client.recreate_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config=VectorParams(size=embed_dim, distance=Distance.COSINE)\n",
    "    )\n",
    "    print(f\"‚úÖ Collection '{COLLECTION_NAME}' ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng.\")\n",
    "\n",
    "    # --- 6. Th√™m c√°c chunk ƒë√£ x·ª≠ l√Ω v√†o Qdrant ---\n",
    "    print(\"‚è≥ ƒêang th·ª±c hi·ªán embedding v√† l∆∞u v√†o Qdrant. Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t...\")\n",
    "    # LangChain Qdrant s·∫Ω t·ª± ƒë·ªông x·ª≠ l√Ω vi·ªác g·ªçi embedding_model\n",
    "    qdrant = Qdrant(\n",
    "        client=client,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        embeddings=embedding_model\n",
    "    )\n",
    "\n",
    "    qdrant.add_documents(documents=docs_for_db, batch_size=64)\n",
    "\n",
    "    print(\"\\nüéâ HO√ÄN T·∫§T! To√†n b·ªô d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c embedding v√† l∆∞u v√†o Qdrant.\")\n",
    "    print(f\"üëâ B√¢y gi·ªù b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng collection '{COLLECTION_NAME}' trong Langflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90520d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫Øt ƒë·∫ßu qu√° tr√¨nh tr√≠ch xu·∫•t th√¥ng tin v·ªõi logic 'Chia ƒë·ªÉ tr·ªã'...\n",
      "\n",
      "--- V√íNG L·∫∂P 1/20 | L√¥ c√≤n l·∫°i: 6 ---\n",
      "ƒêang x·ª≠ l√Ω l√¥ g·ªìm 6 tr∆∞·ªùng: ['BBC (B√°o c√°o b·ªüi)', 'CBC (C√°n b·ªô ch√≠nh)', 'ID ƒë·ªÅ xu·∫•t', 'Ng√†y b√°o c√°o', 'Ng√†y c·∫≠p nh·∫≠t', 'M·ª•c ƒë√≠ch th·∫©m ƒë·ªãnh']\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'BBC (B√°o c√°o b·ªüi)': BBC-DN-HANOI\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'CBC (C√°n b·ªô ch√≠nh)': CBC-KHDN-LON\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'ID ƒë·ªÅ xu·∫•t': DX-2024-8868\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Ng√†y b√°o c√°o': 05 th√°ng 10 nƒÉm 2024\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Ng√†y c·∫≠p nh·∫≠t': 02/10/2024\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'M·ª•c ƒë√≠ch th·∫©m ƒë·ªãnh': C·∫•p m·ªõi\n",
      "\n",
      "--- V√íNG L·∫∂P 2/20 | L√¥ c√≤n l·∫°i: 5 ---\n",
      "ƒêang x·ª≠ l√Ω l√¥ g·ªìm 6 tr∆∞·ªùng: ['C·∫•p n∆°i', 'ID T24', 'X·∫øp h·∫°ng t√≠n d·ª•ng', 'Ng√†y x·∫øp h·∫°ng', 'K·∫øt qu·∫£ ph√¢n nh√≥m ti·∫øp c·∫≠n', 'Ng√†nh']\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'C·∫•p n∆°i': H·ªôi s·ªü ch√≠nh\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'ID T24': 10034598\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'X·∫øp h·∫°ng t√≠n d·ª•ng': A3\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Ng√†y x·∫øp h·∫°ng': 01/10/2024\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'K·∫øt qu·∫£ ph√¢n nh√≥m ti·∫øp c·∫≠n': Nh√≥m 2\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Ng√†nh': R·ªßi ro Cao\n",
      "\n",
      "--- V√íNG L·∫∂P 3/20 | L√¥ c√≤n l·∫°i: 4 ---\n",
      "ƒêang x·ª≠ l√Ω l√¥ g·ªìm 6 tr∆∞·ªùng: ['Ph√¢n nh√≥m r·ªßi ro', 'Ph√¢n nh√≥m ·ª©ng x·ª≠', 'Kh√°c bi·ªát HƒêTD', 'K·∫øt qu·∫£ ph√¢n lu·ªìng', 'Lo·∫°i kho·∫£n vay', 'T·ªïng gi√° tr·ªã c·∫•p TD']\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Ph√¢n nh√≥m r·ªßi ro': R·ªßi ro Cao\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Ph√¢n nh√≥m ·ª©ng x·ª≠': Nh√≥m 2\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Kh√°c bi·ªát HƒêTD': C√≥ (ƒê·ªÅ xu·∫•t t·ª∑ l·ªá t√†i tr·ª£ cao h∆°n cho nguy√™n v·∫≠t li·ªáu nh·∫≠p kh·∫©u)\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'K·∫øt qu·∫£ ph√¢n lu·ªìng': Lu·ªìng chuy√™n s√¢u\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Lo·∫°i kho·∫£n vay': Vay v·ªën l∆∞u ƒë·ªông\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'T·ªïng gi√° tr·ªã c·∫•p TD': 200,000 (ƒë∆°n v·ªã: tri·ªáu VND)\n",
      "\n",
      "--- V√íNG L·∫∂P 4/20 | L√¥ c√≤n l·∫°i: 3 ---\n",
      "ƒêang x·ª≠ l√Ω l√¥ g·ªìm 6 tr∆∞·ªùng: ['T·ªïng gi√° tr·ªã c√≥ BPHƒê', 'X·∫øp h·∫°ng r·ªßi ro', 'R·ªßi ro ng√†nh', 'M·ª©c ƒë·ªô ph·ª©c t·∫°p', 'Ti√™u ch√≠ t√†i ch√≠nh', 'M·ª©c ƒë·ªô r·ªßi ro']\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'T·ªïng gi√° tr·ªã c√≥ BPHƒê': 280 t·ª∑ VND\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'X·∫øp h·∫°ng r·ªßi ro': Cao\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'R·ªßi ro ng√†nh': Trung b√¨nh-Cao\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'M·ª©c ƒë·ªô ph·ª©c t·∫°p': Cao (Do c√≥ y·∫øu t·ªë giao d·ªãch qu·ªëc t·∫ø v√† quy m√¥ l·ªõn)\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Ti√™u ch√≠ t√†i ch√≠nh': ƒê·∫°t\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'M·ª©c ƒë·ªô r·ªßi ro': Cao\n",
      "\n",
      "--- V√íNG L·∫∂P 5/20 | L√¥ c√≤n l·∫°i: 2 ---\n",
      "ƒêang x·ª≠ l√Ω l√¥ g·ªìm 6 tr∆∞·ªùng: ['T√™n ƒë·∫ßy ƒë·ªß c·ªßa doanh nghi·ªáp', 'Ng√†y th√†nh l·∫≠p', 'Lo·∫°i h√¨nh c√¥ng ty', 'M√¥ t·∫£ ho·∫°t ƒë·ªông kinh doanh', 'Ti·∫øn ƒë·ªô v·∫≠n xu·∫•t', 'Kh·∫£ nƒÉng l·∫≠p k·∫ø ho·∫°ch']\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'T√™n ƒë·∫ßy ƒë·ªß c·ªßa doanh nghi·ªáp': C√îNG TY C·ªî PH·∫¶N BAO B√å TO√ÄN C·∫¶U XANH\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Ng√†y th√†nh l·∫≠p': 15/03/2019\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Lo·∫°i h√¨nh c√¥ng ty': C√¥ng ty c·ªï ph·∫ßn c√≥ v·ªën ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i (100% v·ªën t·ª´ t·∫≠p ƒëo√†n Global Packaging Holdings, Singapore).\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'M√¥ t·∫£ ho·∫°t ƒë·ªông kinh doanh': S·∫£n xu·∫•t v√† kinh doanh c√°c s·∫£n ph·∫©m bao b√¨ c√¥ng nghi·ªáp.\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Ti·∫øn ƒë·ªô v·∫≠n xu·∫•t': - Giai ƒëo·∫°n 1 (2019-2021): X√¢y d·ª±ng nh√† m√°y v√† l·∫Øp ƒë·∫∑t 2 d√¢y chuy·ªÅn c·ªßa ƒê·ª©c. B·∫Øt ƒë·∫ßu s·∫£n xu·∫•t th·ª≠ t·ª´ Q3/2021.\n",
      "- Giai ƒëo·∫°n 2 (2022-nay): V·∫≠n h√†nh 100% c√¥ng su·∫•t 2 d√¢y chuy·ªÅn, ƒë·∫°t doanh thu 1,850 t·ª∑ VND nƒÉm 2023. C√¥ng ty ƒëang l√™n k·∫ø ho·∫°ch ƒë·∫ßu t∆∞ th√™m d√¢y chuy·ªÅn th·ª© 3 v√†o cu·ªëi nƒÉm 2025.\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Kh·∫£ nƒÉng l·∫≠p k·∫ø ho·∫°ch': K·∫ø ho·∫°ch kinh doanh v√† t√†i ch√≠nh ƒë∆∞·ª£c x√¢y d·ª±ng chi ti·∫øt b·ªüi ƒë·ªôi ng≈© chuy√™n gia t·ª´ c√¥ng ty m·∫π, c√≥ ƒë·ªô tin c·∫≠y cao v√† th∆∞·ªùng ƒë·∫°t ho·∫∑c v∆∞·ª£t ch·ªâ ti√™u ƒë·ªÅ ra.\n",
      "\n",
      "--- V√íNG L·∫∂P 6/20 | L√¥ c√≤n l·∫°i: 1 ---\n",
      "ƒêang x·ª≠ l√Ω l√¥ g·ªìm 6 tr∆∞·ªùng: ['T√¨nh h√¨nh ph√°p l√Ω', 'Kinh nghi·ªám ch·ªß s·ªü h·ªØu', 'Ch·∫•t l∆∞·ª£ng quan h·ªá TD', 'C√≥ vi ph·∫°m kh√¥ng', 'Chi ti·∫øt vi ph·∫°m', 'S·ªë th√°ng t∆∞∆°ng t√°c T24']\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'T√¨nh h√¨nh ph√°p l√Ω': C√¥ng ty tu√¢n th·ªß ƒë·∫ßy ƒë·ªß c√°c quy ƒë·ªãnh c·ªßa ph√°p lu·∫≠t Vi·ªát Nam. ƒê√£ ƒë∆∞·ª£c c·∫•p ch·ª©ng ch·ªâ ISO 9001:2015, ISO 14001:2015 v√† ch·ª©ng ch·ªâ FSC v·ªÅ qu·∫£n l√Ω r·ª´ng b·ªÅn v·ªØng. Kh√¥ng c√≥ tranh ch·∫•p, ki·ªán t·ª•ng n√†o ƒëang di·ªÖn ra. B√°o c√°o ki·ªÉm to√°n 2 nƒÉm g·∫ßn nh·∫•t (2022, 2023) b·ªüi PwC c√≥ √Ω ki·∫øn ch·∫•p nh·∫≠n to√†n ph·∫ßn.\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Kinh nghi·ªám ch·ªß s·ªü h·ªØu': T·∫≠p ƒëo√†n Global Packaging Holdings (Singapore), m·ªôt trong nh·ªØng t·∫≠p ƒëo√†n h√†ng ƒë·∫ßu ch√¢u √Å v·ªÅ gi·∫£i ph√°p ƒë√≥ng g√≥i, th√†nh l·∫≠p nƒÉm 1995. T·∫≠p ƒëo√†n c√≥ h∆°n 40 nh√† m√°y t·∫°i 12 qu·ªëc gia, ph·ª•c v·ª• c√°c kh√°ch h√†ng l·ªõn nh∆∞ Apple, Samsung, P&G.\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Ch·∫•t l∆∞·ª£ng quan h·ªá TD': Good\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'C√≥ vi ph·∫°m kh√¥ng': No\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'Chi ti·∫øt vi ph·∫°m': Compliance with credit terms: No violations recorded (as there is no existing credit).\n",
      "Number of violations: 0.\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'S·ªë th√°ng t∆∞∆°ng t√°c T24': 12/12 months\n",
      "\n",
      "--- V√íNG L·∫∂P 7/20 | L√¥ c√≤n l·∫°i: 0 ---\n",
      "ƒêang x·ª≠ l√Ω l√¥ g·ªìm 3 tr∆∞·ªùng: ['S·ªë d∆∞ ti·ªÅn g·ª≠i 12 th√°ng', 'S·ªë l·∫ßn ph√°t sinh giao d·ªãch', 'T·ª∑ l·ªá c√≥ s·ª≠ d·ª•ng SPDV kh√°c']\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'S·ªë d∆∞ ti·ªÅn g·ª≠i 12 th√°ng': {'Average CASA balance': '18,500,000,000 VND (18.5 t·ª∑ VND)', 'Average Term Deposit balance': '50,000,000,000 VND (50 t·ª∑ VND)'}\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'S·ªë l·∫ßn ph√°t sinh giao d·ªãch': > 500 transactions/month\n",
      "    ‚úÖ ƒê√£ t√¨m th·∫•y 'T·ª∑ l·ªá c√≥ s·ª≠ d·ª•ng SPDV kh√°c': {'Payroll service': 'Yes, for 500+ employees.', 'E-banking for corporate': 'Yes, heavy usage.', 'FX & Trade Finance': 'Yes, frequently uses LC and T/T services for import/export.', 'Other services (investment, insurance...)': 'No. Potential for cross-selling.'}\n",
      "\n",
      "\n",
      "‚úÖ Qu√° tr√¨nh tr√≠ch xu·∫•t ho√†n t·∫•t!\n",
      "-----------------------------------------\n",
      "          K·∫æT QU·∫¢ JSON CU·ªêI C√ôNG         \n",
      "-----------------------------------------\n",
      "{\n",
      "    \"BBC (B√°o c√°o b·ªüi)\": \"BBC-DN-HANOI\",\n",
      "    \"CBC (C√°n b·ªô ch√≠nh)\": \"CBC-KHDN-LON\",\n",
      "    \"ID ƒë·ªÅ xu·∫•t\": \"DX-2024-8868\",\n",
      "    \"Ng√†y b√°o c√°o\": \"05 th√°ng 10 nƒÉm 2024\",\n",
      "    \"Ng√†y c·∫≠p nh·∫≠t\": \"02/10/2024\",\n",
      "    \"M·ª•c ƒë√≠ch th·∫©m ƒë·ªãnh\": \"C·∫•p m·ªõi\",\n",
      "    \"C·∫•p n∆°i\": \"H·ªôi s·ªü ch√≠nh\",\n",
      "    \"ID T24\": \"10034598\",\n",
      "    \"X·∫øp h·∫°ng t√≠n d·ª•ng\": \"A3\",\n",
      "    \"Ng√†y x·∫øp h·∫°ng\": \"01/10/2024\",\n",
      "    \"K·∫øt qu·∫£ ph√¢n nh√≥m ti·∫øp c·∫≠n\": \"Nh√≥m 2\",\n",
      "    \"Ng√†nh\": \"R·ªßi ro Cao\",\n",
      "    \"Ph√¢n nh√≥m r·ªßi ro\": \"R·ªßi ro Cao\",\n",
      "    \"Ph√¢n nh√≥m ·ª©ng x·ª≠\": \"Nh√≥m 2\",\n",
      "    \"Kh√°c bi·ªát HƒêTD\": \"C√≥ (ƒê·ªÅ xu·∫•t t·ª∑ l·ªá t√†i tr·ª£ cao h∆°n cho nguy√™n v·∫≠t li·ªáu nh·∫≠p kh·∫©u)\",\n",
      "    \"K·∫øt qu·∫£ ph√¢n lu·ªìng\": \"Lu·ªìng chuy√™n s√¢u\",\n",
      "    \"Lo·∫°i kho·∫£n vay\": \"Vay v·ªën l∆∞u ƒë·ªông\",\n",
      "    \"T·ªïng gi√° tr·ªã c·∫•p TD\": \"200,000 (ƒë∆°n v·ªã: tri·ªáu VND)\",\n",
      "    \"T·ªïng gi√° tr·ªã c√≥ BPHƒê\": \"280 t·ª∑ VND\",\n",
      "    \"X·∫øp h·∫°ng r·ªßi ro\": \"Cao\",\n",
      "    \"R·ªßi ro ng√†nh\": \"Trung b√¨nh-Cao\",\n",
      "    \"M·ª©c ƒë·ªô ph·ª©c t·∫°p\": \"Cao (Do c√≥ y·∫øu t·ªë giao d·ªãch qu·ªëc t·∫ø v√† quy m√¥ l·ªõn)\",\n",
      "    \"Ti√™u ch√≠ t√†i ch√≠nh\": \"ƒê·∫°t\",\n",
      "    \"M·ª©c ƒë·ªô r·ªßi ro\": \"Cao\",\n",
      "    \"T√™n ƒë·∫ßy ƒë·ªß c·ªßa doanh nghi·ªáp\": \"C√îNG TY C·ªî PH·∫¶N BAO B√å TO√ÄN C·∫¶U XANH\",\n",
      "    \"Ng√†y th√†nh l·∫≠p\": \"15/03/2019\",\n",
      "    \"Lo·∫°i h√¨nh c√¥ng ty\": \"C√¥ng ty c·ªï ph·∫ßn c√≥ v·ªën ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i (100% v·ªën t·ª´ t·∫≠p ƒëo√†n Global Packaging Holdings, Singapore).\",\n",
      "    \"M√¥ t·∫£ ho·∫°t ƒë·ªông kinh doanh\": \"S·∫£n xu·∫•t v√† kinh doanh c√°c s·∫£n ph·∫©m bao b√¨ c√¥ng nghi·ªáp.\",\n",
      "    \"Ti·∫øn ƒë·ªô v·∫≠n xu·∫•t\": \"- Giai ƒëo·∫°n 1 (2019-2021): X√¢y d·ª±ng nh√† m√°y v√† l·∫Øp ƒë·∫∑t 2 d√¢y chuy·ªÅn c·ªßa ƒê·ª©c. B·∫Øt ƒë·∫ßu s·∫£n xu·∫•t th·ª≠ t·ª´ Q3/2021.\\n- Giai ƒëo·∫°n 2 (2022-nay): V·∫≠n h√†nh 100% c√¥ng su·∫•t 2 d√¢y chuy·ªÅn, ƒë·∫°t doanh thu 1,850 t·ª∑ VND nƒÉm 2023. C√¥ng ty ƒëang l√™n k·∫ø ho·∫°ch ƒë·∫ßu t∆∞ th√™m d√¢y chuy·ªÅn th·ª© 3 v√†o cu·ªëi nƒÉm 2025.\",\n",
      "    \"Kh·∫£ nƒÉng l·∫≠p k·∫ø ho·∫°ch\": \"K·∫ø ho·∫°ch kinh doanh v√† t√†i ch√≠nh ƒë∆∞·ª£c x√¢y d·ª±ng chi ti·∫øt b·ªüi ƒë·ªôi ng≈© chuy√™n gia t·ª´ c√¥ng ty m·∫π, c√≥ ƒë·ªô tin c·∫≠y cao v√† th∆∞·ªùng ƒë·∫°t ho·∫∑c v∆∞·ª£t ch·ªâ ti√™u ƒë·ªÅ ra.\",\n",
      "    \"T√¨nh h√¨nh ph√°p l√Ω\": \"C√¥ng ty tu√¢n th·ªß ƒë·∫ßy ƒë·ªß c√°c quy ƒë·ªãnh c·ªßa ph√°p lu·∫≠t Vi·ªát Nam. ƒê√£ ƒë∆∞·ª£c c·∫•p ch·ª©ng ch·ªâ ISO 9001:2015, ISO 14001:2015 v√† ch·ª©ng ch·ªâ FSC v·ªÅ qu·∫£n l√Ω r·ª´ng b·ªÅn v·ªØng. Kh√¥ng c√≥ tranh ch·∫•p, ki·ªán t·ª•ng n√†o ƒëang di·ªÖn ra. B√°o c√°o ki·ªÉm to√°n 2 nƒÉm g·∫ßn nh·∫•t (2022, 2023) b·ªüi PwC c√≥ √Ω ki·∫øn ch·∫•p nh·∫≠n to√†n ph·∫ßn.\",\n",
      "    \"Kinh nghi·ªám ch·ªß s·ªü h·ªØu\": \"T·∫≠p ƒëo√†n Global Packaging Holdings (Singapore), m·ªôt trong nh·ªØng t·∫≠p ƒëo√†n h√†ng ƒë·∫ßu ch√¢u √Å v·ªÅ gi·∫£i ph√°p ƒë√≥ng g√≥i, th√†nh l·∫≠p nƒÉm 1995. T·∫≠p ƒëo√†n c√≥ h∆°n 40 nh√† m√°y t·∫°i 12 qu·ªëc gia, ph·ª•c v·ª• c√°c kh√°ch h√†ng l·ªõn nh∆∞ Apple, Samsung, P&G.\",\n",
      "    \"Ch·∫•t l∆∞·ª£ng quan h·ªá TD\": \"Good\",\n",
      "    \"C√≥ vi ph·∫°m kh√¥ng\": \"No\",\n",
      "    \"Chi ti·∫øt vi ph·∫°m\": \"Compliance with credit terms: No violations recorded (as there is no existing credit).\\nNumber of violations: 0.\",\n",
      "    \"S·ªë th√°ng t∆∞∆°ng t√°c T24\": \"12/12 months\",\n",
      "    \"S·ªë d∆∞ ti·ªÅn g·ª≠i 12 th√°ng\": {\n",
      "        \"Average CASA balance\": \"18,500,000,000 VND (18.5 t·ª∑ VND)\",\n",
      "        \"Average Term Deposit balance\": \"50,000,000,000 VND (50 t·ª∑ VND)\"\n",
      "    },\n",
      "    \"S·ªë l·∫ßn ph√°t sinh giao d·ªãch\": \"> 500 transactions/month\",\n",
      "    \"T·ª∑ l·ªá c√≥ s·ª≠ d·ª•ng SPDV kh√°c\": {\n",
      "        \"Payroll service\": \"Yes, for 500+ employees.\",\n",
      "        \"E-banking for corporate\": \"Yes, heavy usage.\",\n",
      "        \"FX & Trade Finance\": \"Yes, frequently uses LC and T/T services for import/export.\",\n",
      "        \"Other services (investment, insurance...)\": \"No. Potential for cross-selling.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "# --- 1. C·∫§U H√åNH ---\n",
    "\n",
    "# URL API c·ªßa pipeline Langflow\n",
    "LANGFLOW_URL = \"http://localhost:7860/api/v1/run/70017ce4-caba-479c-a03c-067faebf3c6c\"\n",
    "\n",
    "# Headers cho request, ch·ªâ ƒë·ªãnh r√µ encoding UTF-8\n",
    "HEADERS = {\"Content-Type\": \"application/json; charset=utf-8\"}\n",
    "\n",
    "# C√°c tham s·ªë cho logic l·∫∑p\n",
    "MAX_ITERATIONS = 20      # TƒÉng s·ªë l·∫ßn l·∫∑p t·ªëi ƒëa v√¨ c√≥ th·ªÉ ph·∫£i chia nh·ªè nhi·ªÅu l·∫ßn\n",
    "INITIAL_BATCH_SIZE = 6 # S·ªë tr∆∞·ªùng th√¥ng tin h·ªèi trong l√¥ ban ƒë·∫ßu\n",
    "MIN_BATCH_SIZE_TO_SPLIT = 2 # Ch·ªâ chia nh·ªè l√¥ n·∫øu n√≥ c√≤n nhi·ªÅu h∆°n 1 tr∆∞·ªùng\n",
    "\n",
    "# Danh s√°ch c√°c tr∆∞·ªùng th√¥ng tin c·∫ßn tr√≠ch xu·∫•t (ho√†n to√†n b·∫±ng ti·∫øng Vi·ªát)\n",
    "NEW_TEMPLATE_MAPPING = {\n",
    "    \"headerInfo\": {\n",
    "        \"bbc\": \"BBC (B√°o c√°o b·ªüi)\",\n",
    "        \"cbc\": \"CBC (C√°n b·ªô ch√≠nh)\",\n",
    "        \"idDeXuat\": \"ID ƒë·ªÅ xu·∫•t\",\n",
    "        \"ngayBaoCao\": \"Ng√†y b√°o c√°o\",\n",
    "        \"ngayCapNhat\": \"Ng√†y c·∫≠p nh·∫≠t\",\n",
    "        \"mucDichThamDinh\": \"M·ª•c ƒë√≠ch th·∫©m ƒë·ªãnh\",\n",
    "        \"capNoi\": \"C·∫•p n∆°i\",\n",
    "    },\n",
    "    \"creditInfo\": {\n",
    "        \"idT24\": \"ID T24\",\n",
    "        \"xepHangTinDung\": \"X·∫øp h·∫°ng t√≠n d·ª•ng\",\n",
    "        \"ngayXepHang\": \"Ng√†y x·∫øp h·∫°ng\",\n",
    "        \"ketQuaPhanNhomTiepCan\": \"K·∫øt qu·∫£ ph√¢n nh√≥m ti·∫øp c·∫≠n\",\n",
    "        \"nganh\": \"Ng√†nh\",\n",
    "        \"phanNhomRuiRo\": \"Ph√¢n nh√≥m r·ªßi ro\",\n",
    "        \"phanNhomUngXu\": \"Ph√¢n nh√≥m ·ª©ng x·ª≠\",\n",
    "        \"khacBietHDTD\": \"Kh√°c bi·ªát HƒêTD\",\n",
    "        \"ketQuaPhanLuong\": \"K·∫øt qu·∫£ ph√¢n lu·ªìng\",\n",
    "        \"loaiKhoanVay\": \"Lo·∫°i kho·∫£n vay\",\n",
    "        \"tongGiaTriCapTD\": \"T·ªïng gi√° tr·ªã c·∫•p TD\",\n",
    "        \"tongGiaTriCoBPHD\": \"T·ªïng gi√° tr·ªã c√≥ BPHƒê\",\n",
    "        \"xepHangRuiRo\": \"X·∫øp h·∫°ng r·ªßi ro\",\n",
    "        \"ruiRoNganh\": \"R·ªßi ro ng√†nh\",\n",
    "        \"mucDoPhucTap\": \"M·ª©c ƒë·ªô ph·ª©c t·∫°p\",\n",
    "        \"tieuChiTaiChinh\": \"Ti√™u ch√≠ t√†i ch√≠nh\",\n",
    "        \"mucDoRuiRo\": \"M·ª©c ƒë·ªô r·ªßi ro\",\n",
    "    },\n",
    "    \"businessInfo\": {\n",
    "        \"tenDayDu\": \"T√™n ƒë·∫ßy ƒë·ªß c·ªßa doanh nghi·ªáp\",\n",
    "        \"ngayThanhLap\": \"Ng√†y th√†nh l·∫≠p\",\n",
    "        \"loaiHinhCongTy\": \"Lo·∫°i h√¨nh c√¥ng ty\",\n",
    "        \"hoatDongKinhDoanhMoTa\": \"M√¥ t·∫£ ho·∫°t ƒë·ªông kinh doanh\",\n",
    "        \"tienDoVanXuat\": \"Ti·∫øn ƒë·ªô v·∫≠n xu·∫•t\",\n",
    "        \"khaNangLapKeHoach\": \"Kh·∫£ nƒÉng l·∫≠p k·∫ø ho·∫°ch\",\n",
    "    },\n",
    "    \"legalInfo\": {\n",
    "        \"tinhHinhPhapLy\": \"T√¨nh h√¨nh ph√°p l√Ω\",\n",
    "        \"kinhNghiemChuSoHuu\": \"Kinh nghi·ªám ch·ªß s·ªü h·ªØu\",\n",
    "    },\n",
    "    \"tcbRelationship\": {\n",
    "        \"chatLuongQuanHeTD\": \"Ch·∫•t l∆∞·ª£ng quan h·ªá TD\",\n",
    "        \"khongViPham\": \"C√≥ vi ph·∫°m kh√¥ng\",\n",
    "        \"chiTietViPham\": \"Chi ti·∫øt vi ph·∫°m\",\n",
    "        \"soThangTuongTacT24\": \"S·ªë th√°ng t∆∞∆°ng t√°c T24\",\n",
    "        \"soDuTienGui12Thang\": \"S·ªë d∆∞ ti·ªÅn g·ª≠i 12 th√°ng\",\n",
    "        \"soLanPhatSinhGiaoDich\": \"S·ªë l·∫ßn ph√°t sinh giao d·ªãch\",\n",
    "        \"tiLeCoSuDungSPDVKhac\": \"T·ª∑ l·ªá c√≥ s·ª≠ d·ª•ng SPDV kh√°c\",\n",
    "    },\n",
    "    # C√°c tr∆∞·ªùng ph·ª©c t·∫°p (array) s·∫Ω ƒë∆∞·ª£c x·ª≠ l√Ω sau\n",
    "    \"management\": {},\n",
    "    \"financialStatus\": {},\n",
    "}\n",
    "\n",
    "FIELDS_TO_EXTRACT = []\n",
    "# T·∫°o th√™m reverse map: key -> section\n",
    "KEY_TO_SECTION = {}\n",
    "for section, fields in NEW_TEMPLATE_MAPPING.items():\n",
    "    for key, value in fields.items():\n",
    "        FIELDS_TO_EXTRACT.append(value)\n",
    "        KEY_TO_SECTION[key] = section\n",
    "\n",
    "# --- 2. C√ÅC H√ÄM H·ªñ TR·ª¢ ---\n",
    "\n",
    "def create_prompt(fields_list: list) -> str:\n",
    "    \"\"\"T·∫°o prompt ƒë·ªông d·ª±a tr√™n s·ªë l∆∞·ª£ng tr∆∞·ªùng c·∫ßn h·ªèi.\"\"\"\n",
    "    if not fields_list:\n",
    "        return \"\"\n",
    "    \n",
    "    # T·∫°o danh s√°ch c√°c tr∆∞·ªùng d∆∞·ªõi d·∫°ng m·ªôt chu·ªói text thu·∫ßn t√∫y\n",
    "    fields_as_text_list = \"\\n- \".join(fields_list)\n",
    "    \n",
    "    # Thay ƒë·ªïi c√¢u l·ªánh prompt ƒë·ªÉ r√µ r√†ng h∆°n v·ªõi LLM\n",
    "    if len(fields_list) == 1:\n",
    "        # Prompt t·∫≠p trung v√†o m·ªôt tr∆∞·ªùng duy nh·∫•t\n",
    "        return f\"{fields_as_text_list}\"\n",
    "    else:\n",
    "        # Prompt cho m·ªôt danh s√°ch c√°c tr∆∞·ªùng\n",
    "        return f\"\"\"\n",
    "- {fields_as_text_list}\n",
    "\"\"\"\n",
    "\n",
    "def is_valid_value(value) -> bool:\n",
    "    \"\"\"Ki·ªÉm tra xem gi√° tr·ªã tr·∫£ v·ªÅ c√≥ h·ª£p l·ªá kh√¥ng (kh√¥ng ph·∫£i None, kh√¥ng r·ªóng).\"\"\"\n",
    "    return value is not None and str(value).strip() != \"\"\n",
    "\n",
    "def query_langflow_for_json(question_prompt: str) -> dict:\n",
    "    \"\"\"\n",
    "    G·ª≠i m·ªôt prompt ƒë·∫øn Langflow, nh·∫≠n ph·∫£n h·ªìi v√† c·ªë g·∫Øng tr√≠ch xu·∫•t m·ªôt ƒë·ªëi t∆∞·ª£ng JSON.\n",
    "    (H√†m n√†y gi·ªØ nguy√™n nh∆∞ c≈©, kh√¥ng c·∫ßn thay ƒë·ªïi)\n",
    "    \"\"\"\n",
    "    if not question_prompt:\n",
    "        return {}\n",
    "    payload = {\n",
    "        \"input_value\": question_prompt, \"output_type\": \"chat\", \"input_type\": \"chat\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(LANGFLOW_URL, json=payload, headers=HEADERS, timeout=120)\n",
    "        response.raise_for_status()\n",
    "        langflow_data = json.loads(response.text)\n",
    "        llm_response_text = langflow_data['outputs'][0]['outputs'][0]['results']['message']['text']\n",
    "        start = llm_response_text.find('{')\n",
    "        end = llm_response_text.rfind('}')\n",
    "        if start != -1 and end != -1:\n",
    "            json_str = llm_response_text[start : end + 1]\n",
    "            return json.loads(json_str)\n",
    "        else:\n",
    "            print(\"  - L·ªói: Kh√¥ng t√¨m th·∫•y ƒë·ªëi t∆∞·ª£ng JSON h·ª£p l·ªá trong ph·∫£n h·ªìi c·ªßa LLM.\")\n",
    "            return {}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"  - L·ªói k·∫øt n·ªëi API: {e}\")\n",
    "        return {}\n",
    "    except (KeyError, IndexError):\n",
    "        print(\"  - L·ªói: C·∫•u tr√∫c JSON tr·∫£ v·ªÅ t·ª´ Langflow kh√¥ng nh∆∞ mong ƒë·ª£i.\")\n",
    "        pprint(langflow_data)\n",
    "        return {}\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"  - L·ªói: Kh√¥ng th·ªÉ ph√¢n t√≠ch JSON t·ª´ ph·∫£n h·ªìi c·ªßa LLM. {e}\")\n",
    "        print(f\"  - Ph·∫£n h·ªìi g·ªëc t·ª´ LLM: {llm_response_text}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# --- 3. LOGIC TR√çCH XU·∫§T \"CHIA ƒê·ªÇ TR·ªä\" ---\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    H√†m ch√≠nh ƒëi·ªÅu khi·ªÉn lu·ªìng tr√≠ch xu·∫•t th√¥ng tin th√¥ng minh.\n",
    "    S·ª≠ d·ª•ng m·ªôt h√†ng ƒë·ª£i (queue) ƒë·ªÉ qu·∫£n l√Ω c√°c l√¥ c√¥ng vi·ªác.\n",
    "    N·∫øu m·ªôt l√¥ th·∫•t b·∫°i, n√≥ s·∫Ω ƒë∆∞·ª£c chia nh·ªè v√† th√™m l·∫°i v√†o h√†ng ƒë·ª£i.\n",
    "    \"\"\"\n",
    "    final_result = {}\n",
    "    \n",
    "    # Kh·ªüi t·∫°o h√†ng ƒë·ª£i c√¥ng vi·ªác (work queue)\n",
    "    # Ban ƒë·∫ßu, chia to√†n b·ªô danh s√°ch th√†nh c√°c l√¥ c√≥ k√≠ch th∆∞·ªõc `INITIAL_BATCH_SIZE`\n",
    "    work_queue = [\n",
    "        FIELDS_TO_EXTRACT[i:i + INITIAL_BATCH_SIZE]\n",
    "        for i in range(0, len(FIELDS_TO_EXTRACT), INITIAL_BATCH_SIZE)\n",
    "    ]\n",
    "    \n",
    "    current_iteration = 0\n",
    "    print(\"üöÄ B·∫Øt ƒë·∫ßu qu√° tr√¨nh tr√≠ch xu·∫•t th√¥ng tin v·ªõi logic 'Chia ƒë·ªÉ tr·ªã'...\")\n",
    "\n",
    "    # V√≤ng l·∫∑p s·∫Ω ti·∫øp t·ª•c khi v·∫´n c√≤n vi·ªác trong h√†ng ƒë·ª£i v√† ch∆∞a v∆∞·ª£t qu√° gi·ªõi h·∫°n\n",
    "    while work_queue and current_iteration < MAX_ITERATIONS:\n",
    "        current_iteration += 1\n",
    "        \n",
    "        # L·∫•y l√¥ c√¥ng vi·ªác ti·∫øp theo t·ª´ ƒë·∫ßu h√†ng ƒë·ª£i\n",
    "        current_batch = work_queue.pop(0)\n",
    "        \n",
    "        print(f\"\\n--- V√íNG L·∫∂P {current_iteration}/{MAX_ITERATIONS} | L√¥ c√≤n l·∫°i: {len(work_queue)} ---\")\n",
    "        print(f\"ƒêang x·ª≠ l√Ω l√¥ g·ªìm {len(current_batch)} tr∆∞·ªùng: {current_batch}\")\n",
    "        \n",
    "        # T·∫°o prompt v√† g·ª≠i y√™u c·∫ßu\n",
    "        prompt = create_prompt(current_batch)\n",
    "        response_json = query_langflow_for_json(prompt)\n",
    "\n",
    "        newly_found_fields = []\n",
    "        if response_json:\n",
    "            for field in current_batch:\n",
    "                # Ki·ªÉm tra xem tr∆∞·ªùng c√≥ trong ph·∫£n h·ªìi v√† c√≥ gi√° tr·ªã h·ª£p l·ªá kh√¥ng\n",
    "                if field in response_json and is_valid_value(response_json[field]):\n",
    "                    value = response_json[field]\n",
    "                    print(f\"    ‚úÖ ƒê√£ t√¨m th·∫•y '{field}': {value}\")\n",
    "                    final_result[field] = value\n",
    "                    newly_found_fields.append(field)\n",
    "        \n",
    "        # *** LOGIC \"CHIA ƒê·ªÇ TR·ªä\" N·∫∞M ·ªû ƒê√ÇY ***\n",
    "        \n",
    "        # X√°c ƒë·ªãnh c√°c tr∆∞·ªùng ch∆∞a t√¨m ƒë∆∞·ª£c trong l√¥ n√†y\n",
    "        failed_fields = [f for f in current_batch if f not in newly_found_fields]\n",
    "        \n",
    "        if failed_fields:\n",
    "            print(f\"  - Kh√¥ng t√¨m th·∫•y {len(failed_fields)} tr∆∞·ªùng: {failed_fields}\")\n",
    "            \n",
    "            # N·∫øu l√¥ th·∫•t b·∫°i c√≤n ƒë·ªß l·ªõn ƒë·ªÉ chia, th√¨ chia ƒë√¥i n√≥ ra\n",
    "            if len(failed_fields) >= MIN_BATCH_SIZE_TO_SPLIT:\n",
    "                print(f\"  -> splitting_batch Chia nh·ªè l√¥ th·∫•t b·∫°i v√† th√™m l·∫°i v√†o h√†ng ƒë·ª£i.\")\n",
    "                mid_point = len(failed_fields) // 2\n",
    "                first_half = failed_fields[:mid_point]\n",
    "                second_half = failed_fields[mid_point:]\n",
    "                \n",
    "                # Th√™m 2 l√¥ nh·ªè h∆°n v√†o ƒê·∫¶U h√†ng ƒë·ª£i ƒë·ªÉ ƒë∆∞·ª£c ∆∞u ti√™n x·ª≠ l√Ω ngay\n",
    "                work_queue.insert(0, second_half)\n",
    "                work_queue.insert(0, first_half)\n",
    "            else:\n",
    "                # N·∫øu l√¥ qu√° nh·ªè ƒë·ªÉ chia (ch·ªâ c√≤n 1 tr∆∞·ªùng), ta coi nh∆∞ th·∫•t b·∫°i cu·ªëi c√πng\n",
    "                print(f\"  -> L√¥ qu√° nh·ªè, kh√¥ng chia n·ªØa. Ghi nh·∫≠n l√† kh√¥ng t√¨m th·∫•y.\")\n",
    "                # Ch√∫ng ta s·∫Ω b√°o c√°o c√°c tr∆∞·ªùng n√†y ·ªü cu·ªëi\n",
    "        \n",
    "        time.sleep(3) # T·∫°m d·ª´ng gi·ªØa c√°c l·∫ßn g·ªçi API\n",
    "\n",
    "    # --- 4. T·ªîNG K·∫æT ---\n",
    "    print(\"\\n\\n‚úÖ Qu√° tr√¨nh tr√≠ch xu·∫•t ho√†n t·∫•t!\")\n",
    "    \n",
    "    # C√°c tr∆∞·ªùng c√≤n l·∫°i trong h√†ng ƒë·ª£i ho·∫∑c kh√¥ng th·ªÉ t√¨m th·∫•y sau khi chia nh·ªè\n",
    "    remaining_fields = set(FIELDS_TO_EXTRACT) - set(final_result.keys())\n",
    "\n",
    "    if remaining_fields:\n",
    "        print(f\"‚ö†Ô∏è Kh√¥ng th·ªÉ tr√≠ch xu·∫•t {len(remaining_fields)} tr∆∞·ªùng sau:\")\n",
    "        pprint(list(remaining_fields))\n",
    "\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"          K·∫æT QU·∫¢ JSON CU·ªêI C√ôNG         \")\n",
    "    print(\"-----------------------------------------\")\n",
    "    \n",
    "    print(json.dumps(final_result, indent=4, ensure_ascii=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24519e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
